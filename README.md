# DocumentaciÃ³n del proyecto
# Environmental Data ETL Project â€“ JosÃ© Ãngel Pech Xool

This project implements a complete ETL (Extract, Transform, Load) pipeline using Apache Airflow and Docker, designed to collect and unify environmental data from multiple APIs. It targets five Mexican cities and provides insightful dashboards through Streamlit and MongoDB.

---

## Objective

The goal of this project is to gather, process, and visualize data related to:

- ğŸŒ¡ï¸ Current weather conditions
- ğŸ§ª Air pollution indicators (PM10, PM2.5, Ozone)
- ğŸ“ Geographic metadata (state, country, coordinates)

The final result is a Streamlit dashboard that updates hourly and provides a friendly interface to explore environmental conditions across selected cities in Mexico.

---

## Tech Stack

| Tool | Purpose |
| ---- | ------- |
| **Python**    | Core scripting and data processing            |
| **Airflow**   | Workflow orchestration (DAGs, Tasks)          |
| **MongoDB**   | NoSQL database for storing raw and clean data |
| **Docker**    | Containerization of all services              |
| **Streamlit** | Interactive dashboard frontend                |
| **Plotly**    | Visualizations (maps, charts)                 |
| **Pandas**    | Data manipulation                             |

---

## Folder Structure

etl-joseangel/
â”‚
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ main_pipeline.py           # Central Airflow DAG
â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â”œâ”€â”€ ingest_geonames.py     # Ingest GeoNames API
â”‚   â”‚   â”œâ”€â”€ ingest_openweather.py  # Ingest OpenWeather API
â”‚   â”‚   â”œâ”€â”€ ingest_air_quality.py  # Ingest Open-Meteo API
â”‚   â”‚   â”œâ”€â”€ transform_data.py      # Data cleaning/transformation
â”‚   â”‚   â””â”€â”€ load_to_mongodb.py     # Load to MongoDB
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ cities.py              # Target cities (lat, lon, names)
â”‚       â””â”€â”€ mongo_utils.py         # MongoDB connection helpers
â”‚
â”œâ”€â”€ app.py                         # Streamlit dashboard
â”œâ”€â”€ Dockerfile                     # Streamlit container
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ docker-compose.yml             # Multi-service orchestration
â””â”€â”€ README.txt                     # Documentation (this file)

---


## APIs Used

1. **GeoNames API** - `http://api.geonames.org/findNearbyPlaceNameJSON`
2. **OpenWeather API** - `http://api.openweathermap.org/data/2.5/weather`
3. **Open-Meteo Air Quality API** - `https://air-quality-api.open-meteo.com/v1/air-quality`

---

## ğŸ  Target Cities

- MÃ©rida, YucatÃ¡n
- Ciudad del Carmen, Campeche
- Mexico City, CDMX
- Monterrey, Nuevo LeÃ³n
- Hermosillo, Sonora

---

## âš™ï¸ How to Run

1. Clone the repository:
   git clone https://github.com/your-repo/etl-joseangel.git

2. The API keys are loaded from the `.env` file.

3. Start services:
   docker-compose up --build -d

4. Initialize Airflow (first time only):
   docker-compose exec airflow-webserver airflow db init

---

## ğŸ§² MongoDB Collections

- raw_geonames
- raw_air_quality
- raw_weather
- processed_environmental

---

## ğŸ“Š Dashboard Features

- Map of Mexico with city markers
- Hourly temperature trends
- Pollution indicators
- Alert messages for heat or pollution

---

## â±ï¸ ETL Execution Logic

[Ingest GeoNames] â†’ [Ingest OpenWeather] â†’ [Ingest Air Quality] â†’ [Transform Data] â†’ [Load to MongoDB]

---

## ğŸ“Š Future Improvements

- Add more cities or countries
- Historical trends
- Email alerts
- More environmental APIs

---

## ğŸ“œ Author

JosÃ© Ãngel Pech Xool
ETL Project â€“ Universidad PolitÃ©cnica de YucatÃ¡n
July 2025
